<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">



<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.thebetterkong.cn","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"manual"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="现在大学上课，老师一般都是通过学校的课程网站来分享课程的课件等资源。但是，在果壳大课程网站上下载资源，总是需要一项一项的点入，再单击下载，显得十分麻烦，特别有时囤积了大量资源需要去下载，还得比对一下哪些没有下载，这对于我这种数据强迫症的人来说，十分不友好！恰巧那会对爬虫挺感兴趣的，就寻思着拿这个练练手（重在学习），说做就做吧！Let’s go！">
<meta property="og:type" content="article">
<meta property="og:title" content="利用爬虫实现课程网站资源的批量下载">
<meta property="og:url" content="http://www.thebetterkong.cn/2020/05/22/Crawler/CrawlSEPBatchDownload/index.html">
<meta property="og:site_name" content="TheBetterKong">
<meta property="og:description" content="现在大学上课，老师一般都是通过学校的课程网站来分享课程的课件等资源。但是，在果壳大课程网站上下载资源，总是需要一项一项的点入，再单击下载，显得十分麻烦，特别有时囤积了大量资源需要去下载，还得比对一下哪些没有下载，这对于我这种数据强迫症的人来说，十分不友好！恰巧那会对爬虫挺感兴趣的，就寻思着拿这个练练手（重在学习），说做就做吧！Let’s go！">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/head.png">
<meta property="og:image" content="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/findheader.png">
<meta property="og:image" content="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/buildpost1.jpg">
<meta property="og:image" content="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/buildpost2.jpg">
<meta property="og:image" content="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/buildpost3.png">
<meta property="og:image" content="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/tocoursesite1.jpg">
<meta property="og:image" content="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/courseinfo.jpg">
<meta property="article:published_time" content="2020-05-22T09:13:12.000Z">
<meta property="article:modified_time" content="2020-08-14T09:27:53.474Z">
<meta property="article:author" content="TheBetterKong">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Crawler">
<meta property="article:tag" content="Webdriver">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/head.png">

<link rel="canonical" href="http://www.thebetterkong.cn/2020/05/22/Crawler/CrawlSEPBatchDownload/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>利用爬虫实现课程网站资源的批量下载 | TheBetterKong</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="TheBetterKong" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">TheBetterKong</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">自律即自由</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.thebetterkong.cn/2020/05/22/Crawler/CrawlSEPBatchDownload/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="TheBetterKong">
      <meta itemprop="description" content="知行合一">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TheBetterKong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          利用爬虫实现课程网站资源的批量下载
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-22 17:13:12" itemprop="dateCreated datePublished" datetime="2020-05-22T17:13:12+08:00">2020-05-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-14 17:27:53" itemprop="dateModified" datetime="2020-08-14T17:27:53+08:00">2020-08-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Crawler/" itemprop="url" rel="index"><span itemprop="name">Crawler</span></a>
                </span>
            </span>

          
            <span id="/2020/05/22/Crawler/CrawlSEPBatchDownload/" class="post-meta-item leancloud_visitors" data-flag-title="利用爬虫实现课程网站资源的批量下载" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/05/22/Crawler/CrawlSEPBatchDownload/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/05/22/Crawler/CrawlSEPBatchDownload/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <div align="center"> <img src="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/head.png" width="100%" alt="head.png" /> </div>   

<p>现在大学上课，老师一般都是通过学校的课程网站来分享课程的课件等资源。但是，在果壳大课程网站上下载资源，总是需要一项一项的点入，再单击下载，显得十分麻烦，特别有时囤积了大量资源需要去下载，还得比对一下哪些没有下载，这对于我这种数据强迫症的人来说，十分不友好！<br>恰巧那会对爬虫挺感兴趣的，就寻思着拿这个练练手（重在学习），说做就做吧！Let’s go！</p>
<a id="more"></a>
<h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><p>首先，得先定我的需求：</p>
<ol>
<li>可以选择课程，对该课程的所有课件实现一键下载；</li>
<li>鉴于我的数据强迫症，课件下载完毕后，应该能向我反馈下载的信息，主要就是新下载了哪些课件；</li>
<li>由于疫情的特殊原因，学校采取了网上授课的方式，但是家里网络不稳定，总是故障，考虑下载视频到本地观看，也便于课后复习；（想想以前，为了能课后复习，都是拿着电脑在上课的时候现场录的）；</li>
</ol>
<p>现在，需求以及清楚，接下来就是开始捣鼓课程网站的情况；    </p>
<ul>
<li>正常情况下，我们首先需求登录，进入教务系统主页；</li>
<li>然后，进入课程网站主页；</li>
<li>然后，在自己的选课情况中，选择课程，进入到课程主页；</li>
<li>然后，找到进入该课程主页的资源页面；</li>
<li>进入相关资源，并点击下载；</li>
</ul>
<p>Emmm，用的时候都还好，这么一捋愈发觉得麻烦了……</p>
<h1 id="弯路：webdriver"><a href="#弯路：webdriver" class="headerlink" title="弯路：webdriver"></a>弯路：webdriver</h1><p>果壳大的教育业务平台网址是：<a href="http://sep.ucas.ac.cn/" target="_blank" rel="noopener">http://sep.ucas.ac.cn/</a> ，要想进行后面的操作，首先，就得实现教育业务平台的自动登录；   </p>
<p>起初嘛，刚接触爬虫，对网络也不是特别了解。脑海里冒出来最简单的思路就是：利用 selenium 的 webdriver 模拟登录过程，然后获取 cookies，之后再利用 cookies 登录；</p>
<ol>
<li><code>pip install selenium</code> 安装 selenium；<ul>
<li>selenium 是 ThoughtWorks 提供的一个强大的基于浏览器的开源自动化测试工具。支持的浏览器包括 IE、Chrome 和 Firefox 等；</li>
</ul>
</li>
<li>到相应的官网下载浏览器驱动，我这里下载的是火狐的浏览器驱动；</li>
</ol>
<p>接下来，写段程序测试：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">headers = &#123;</span></span><br><span class="line"><span class="string">    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36'</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_in</span><span class="params">( )</span>:</span></span><br><span class="line">    user = input(<span class="string">"请输入用户名："</span>)</span><br><span class="line">    password = input(<span class="string">"请输入密码："</span>)</span><br><span class="line">    driver = webdriver.Firefox()</span><br><span class="line">    driver.get(<span class="string">'http://sep.ucas.ac.cn/'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#time.sleep(3)</span></span><br><span class="line">    <span class="comment"># 清空登录框</span></span><br><span class="line">    driver.find_element_by_xpath(<span class="string">"./*//input[@id='menhuusername']"</span>).clear()</span><br><span class="line">    <span class="comment"># 自动填入登录用户名</span></span><br><span class="line">    driver.find_element_by_xpath(<span class="string">"./*//input[@id='menhuusername']"</span>).send_keys(user)</span><br><span class="line">    <span class="comment"># 清空密码框</span></span><br><span class="line">    driver.find_element_by_xpath(<span class="string">"./*//input[@id='menhupassword']"</span>).clear()</span><br><span class="line">    <span class="comment"># 自动填入登录密码</span></span><br><span class="line">    driver.find_element_by_xpath(<span class="string">"./*//input[@id='menhupassword']"</span>).send_keys(password)</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 点击登录按钮进行登录</span></span><br><span class="line">    driver.find_element_by_class_name(<span class="string">'loginbtn'</span>).click()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取cookies</span></span><br><span class="line">    cookie_items = driver.get_cookies()</span><br><span class="line">    cookie = [item[<span class="string">"name"</span>] + <span class="string">"="</span> + item[<span class="string">"value"</span>] <span class="keyword">for</span> item <span class="keyword">in</span> cookie_items]</span><br><span class="line">    cookie_str = <span class="string">';'</span>.join(item <span class="keyword">for</span> item <span class="keyword">in</span> cookie)</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'cookie.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(cookie_str)</span><br><span class="line">    f.close()</span><br><span class="line">    print(<span class="string">"已获取到cookies！"</span>)</span><br><span class="line"></span><br><span class="line">    headers_cookie = &#123;</span><br><span class="line">        <span class="string">"Cookie"</span>: cookie_str  <span class="comment"># 通过接口请求时需要cookies等信息</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    session = requests.session()</span><br><span class="line">    session.post(<span class="string">'http://sep.ucas.ac.cn/'</span>, headers=headers_cookie)</span><br><span class="line">    print(<span class="string">'登录系统成功……'</span>)</span><br><span class="line">    <span class="keyword">return</span> session</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    session = log_in()</span><br></pre></td></tr></table></figure></p>
<p>本以为，万事大吉，结果运行测试，emmmmm……才意识到，还得输入验证码！   </p>
<p>那就继续造：</p>
<ul>
<li>要用到图形处理，所以 <code>pip install pillow</code>；<ul>
<li>坑：安装 pillow，但是导入的时候是 PIL；</li>
</ul>
</li>
<li>抓取下来验证码，还不够，肯定还得识别验证码内容，选择百度文字识别的 OCR，<code>pip install baidu_api</code>；</li>
</ul>
<blockquote>
<p>pillow 的原身是 PIL（Python Imaging Library），PIL 是 Python 图像处理标准库，功能非常强大，API 却非常简单易用；<br>但是 PIL 仅支持到 Python 2.7，后来由志愿者在此基础上创建了兼容的版本，即：Pillow，支持最新Python 3.x，又加入了许多新特性<br>百度文字识别的OCR，即：Optical Character Recognition，光学字符识别</p>
</blockquote>
<p>然后，在上面代码的基础上，新增如下内容：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 导入下载的第三方库</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> aip <span class="keyword">import</span> AipOcr</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 查找验证码</span></span><br><span class="line">png = driver.find_element_by_id(<span class="string">'captcha_img'</span>)  <span class="comment"># 查找验证码元素</span></span><br><span class="line">png.screenshot(<span class="string">'captcha.png'</span>)  <span class="comment"># 对验证码截图并保存</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 验证码处理</span></span><br><span class="line"><span class="comment"># 用 pillow 库对验证码进行图像处理，提高验证码的识别率；</span></span><br><span class="line"><span class="comment"># 处理方法：</span></span><br><span class="line"><span class="comment">#   1.先将图像转换成灰度模式</span></span><br><span class="line"><span class="comment">#   2.通过对阈值的调整使得多余的噪点消失</span></span><br><span class="line">img = Image.open(<span class="string">'captcha.png'</span>)</span><br><span class="line">img = img.convert(<span class="string">'L'</span>)  <span class="comment"># P模式转换为L模式(灰度模式默认阈值127)</span></span><br><span class="line">count = <span class="number">165</span>  <span class="comment"># 设定阈值</span></span><br><span class="line">table = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">256</span>):</span><br><span class="line">    <span class="keyword">if</span> i &lt; count:</span><br><span class="line">        table.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        table.append(<span class="number">1</span>)</span><br><span class="line">img = img.point(table, <span class="string">'1'</span>)</span><br><span class="line">img.save(<span class="string">'captcha1.png'</span>)  <span class="comment"># 保存处理后的验证码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 验证码识别</span></span><br><span class="line"><span class="comment"># 调用 baidu_api 的通用文字识别接口</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 识别码</span></span><br><span class="line">APP_ID = <span class="string">'***'</span></span><br><span class="line">API_KEY = <span class="string">'***'</span></span><br><span class="line">SECRET_KEY = <span class="string">'***'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化对象</span></span><br><span class="line">client = AipOcr(APP_ID, API_KEY, SECRET_KEY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_file_content</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">return</span> f.read()</span><br><span class="line">image = get_file_content(<span class="string">'captcha.png'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义参数变量</span></span><br><span class="line">options = &#123;<span class="string">'language_type'</span>: <span class="string">'ENG'</span>, &#125;  <span class="comment"># 识别语言类型，默认为'CHN_ENG'中英文混合</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用通用文字识别</span></span><br><span class="line">result = client.basicGeneral(image, options)  <span class="comment"># 高精度接口 basicAccurate</span></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> result[<span class="string">'words_result'</span>]:</span><br><span class="line">    captcha = (word[<span class="string">'words'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出，检查结果</span></span><br><span class="line">print(<span class="string">'识别结果：'</span> + captcha)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清空验证码框</span></span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='menhucaptcha']"</span>).clear()</span><br><span class="line"><span class="comment"># 自动填入验证码</span></span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='menhucaptcha']"</span>).send_keys(captcha)</span><br></pre></td></tr></table></figure></p>
<p>至此，总算是完成了登录过程，麻不麻烦？<br>肯定麻烦啊！而且有个很大的问题，就是每次运行会启动 webdriver，把程序拖得很慢，十分影响使用体验，所以我后来才改用了其他方法；</p>
<p>但是也不得不说，这段弯路也让我学到了挺多东西，还是很有意义的！</p>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>其实说正解不太准确，只是说这个办法更加简单易行罢了；</p>
<p>之所以会突然又提出新的办法，是因为有一次，我发现果壳大的综合信息网（ <a href="http://onestop.ucas.ac.cn/" target="_blank" rel="noopener">http://onestop.ucas.ac.cn/</a> ）也可以登录到教育业务平台，而且在这里登录<strong>不需要验证码！</strong><br>这下子，终于可以去掉上面那繁琐的验证码处理过程了。   </p>
<p>但是，这只解决了一个问题，还是无法让我摆脱 webdriver。于是，我寻思这么难顶的资源下载方式，难道就没有前人 “种个树”？再仔细搜了搜，还真有！</p>
<p>原作者的程序是一键下载课程网站<strong>所有课程所有课件</strong>，呃……，对我来说有点夸张了，毕竟几十门课程，怎么得也有个几百项资源吧？也许对于一个爬虫来说爬取这些资源不算什么，但是，还有好多资源我可能不那么需要，事后还得整理。不过无妨，程序框架在这了，修改起来也简单。     </p>
<p>确定修改目标：</p>
<ol>
<li>能够输出选课的课程目录，供按课程批量下载课件；</li>
<li>加入视频下载功能；</li>
</ol>
<p><strong>开干！！！</strong></p>
<h2 id="网站登录"><a href="#网站登录" class="headerlink" title="网站登录"></a>网站登录</h2><p>首先，是登录信息，这里采用了直接将登录信息保存在 txt 文本文件里，避免了我原先那样每次运行脚本都需要手动输入的尴尬。简单的文本处理：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">        <span class="comment">#读取登录信息，第一行存账号，第二行存密码</span></span><br><span class="line">        config = open(<span class="string">"user.txt"</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        line = config.readline().split()</span><br><span class="line">        username = line[<span class="number">0</span>]</span><br><span class="line">        password = line[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">except</span> IOError <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br></pre></td></tr></table></figure></p>
<p>重点来了，这次登录改用了 requests 库的 session 会话对象，构造 post 表单的方式实现登录，并且由于 session 对象的特性，也便于我们后续其他页面的操作；</p>
<blockquote>
<p>session 的特性体现在它的作用时间：从用户到达某个特定的 Web 页开始，到该用户离开 Web 站点，或在程序中利用代码终止某个 Session 结束。<br>引用 Session 则可以让一个用户访问多个页面，之间的切换也会保留该用户的信息；<br>说白了，就是一旦我们使用 session 成功的登录了某个网站后，则在再次使用该 session对象求求该网站的其他网页都会默认使用该 session 之前使用的 cookie 等参数；<br>详细用法参见文章：<a href="https://www.cnblogs.com/linxiyue/p/3980003.html" target="_blank" rel="noopener">Python Requests库：HTTP for Humans</a></p>
</blockquote>
<ol>
<li>构造请求头：<ul>
<li>打开网页（ <a href="http://onestop.ucas.ac.cn/" target="_blank" rel="noopener">http://onestop.ucas.ac.cn/</a> ），然后进入开发者模式；<br><img src="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/findheader.png" alt="findheader"></li>
<li><code>Accept</code>：用户代理期望的 MIME 类型列表，不用管；</li>
<li><code>Accept-Encoding</code>：用户代理支持的压缩方法，不用管；</li>
<li><code>Accept-language</code>：用户代理期望的页面语言，不用管；</li>
<li><code>Connection</code>：决定当前的事务完成后，是否会关闭网络连接。如果该值是“keep-alive”，网络连接就是持久的，不会关闭，使得对同一个服务器的请求可以继续在该连接上完成。因此，需要设置；</li>
<li><code>Cookie</code>：就不用说了，我们目标就是自动获取<strong>登录后</strong>的 cookie；</li>
<li><code>host</code>：指明服务器域名，需要设置；</li>
<li><code>upgrade-insecure-requests</code>：用来向服务器端发送信号，表示客户端优先选择加密及带有身份验证的响应，并且它可以成功处理 upgrade-insecure-requests CSP 指令。</li>
<li><code>User-Agent</code>；指明用户代理软件的应用类型、操作系统、软件开发商以及版本号；</li>
<li>更多详情可见：『<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers" target="_blank" rel="noopener">MDN web docs</a>』</li>
</ul>
</li>
<li>构造 post 表单：<ul>
<li>打开网页（ <a href="http://onestop.ucas.ac.cn/" target="_blank" rel="noopener">http://onestop.ucas.ac.cn/</a> ），然后进入开发者模式（未登录状态）；<br><img src="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/buildpost1.jpg" alt="buildpost1"><ul>
<li><code>Preserve log</code>：保留 log 信息；</li>
<li><code>XHR</code>：（XMLHttpRequest）筛选出与服务器的交互信息；</li>
</ul>
</li>
<li>然后，开发者模式设置完成后，在浏览器输入信息登录（不要关闭开发窗口）；<br><img src="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/buildpost2.jpg" alt="buildpost2"></li>
<li>很明显，我所需要的信息应该在 Name = 0，的那条记录里，打开这条记录；<br><img src="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/buildpost3.png" alt="buildpost3"></li>
<li>在 Form Data 里就有我们构造 post 表单所需要去构造的信息，为：用户名、密码、是否记住密码，这三个字段；</li>
</ul>
</li>
</ol>
<p>这一部分代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">session = requests.session()  <span class="comment"># 创建 session 对象</span></span><br><span class="line">login_url = <span class="string">'http://onestop.ucas.ac.cn/'</span>  <span class="comment"># 更换为不需要验证码登录的地址</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 构造请求头</span></span><br><span class="line">headers=  &#123;</span><br><span class="line">            <span class="string">'Host'</span>: <span class="string">'onestop.ucas.ac.cn'</span>,</span><br><span class="line">            <span class="string">"Connection"</span>: <span class="string">"keep-alive"</span>,</span><br><span class="line">            <span class="string">'Referer'</span>: <span class="string">'http://onestop.ucas.ac.cn/home/index'</span>,</span><br><span class="line">            <span class="string">'X-Requested-With'</span>: <span class="string">'XMLHttpRequest'</span>,  <span class="comment"># 指明 Ajax 请求(异步)，注意，这样返回的数据是 json 类型</span></span><br><span class="line">            <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36"</span>,</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">### 构造表单数据</span></span><br><span class="line">post_data = &#123; </span><br><span class="line">            <span class="string">"username"</span>: username,</span><br><span class="line">            <span class="string">"password"</span>: password,</span><br><span class="line">            <span class="string">"remember"</span>: <span class="string">'checked'</span>,</span><br><span class="line">        &#125;</span><br><span class="line">html = session.post(login_url, data=post_data, headers=headers).text <span class="comment"># 请求，并建立 session</span></span><br><span class="line"><span class="comment"># 将返回的 json 数据转换为 html 文本保存</span></span><br><span class="line">res = json.loads(html)</span><br><span class="line">html = session.get(res[<span class="string">'msg'</span>]).text</span><br><span class="line">print(<span class="string">'登录系统成功！'</span>)</span><br><span class="line"><span class="comment"># save_html(html)  # 用来保存 html 文本做检测</span></span><br></pre></td></tr></table></figure>
<p>这样，我们就有了一个建立了连接的 session，以后就可以利用该 session 完成其他页面的操作；</p>
<h2 id="进入课程网站"><a href="#进入课程网站" class="headerlink" title="进入课程网站"></a>进入课程网站</h2><p>首先，查找进入课程网站的 url：<br><img src="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/tocoursesite1.jpg" alt="tocoursesite1">    </p>
<p>利用之前的 session 访问：<code>h_k = session.get(url)</code></p>
<p>这里有个注意点，在我们直接点击课程网站图标时，会进入一个跳转页面，而我们刚刚 session 访问到的就是这个跳转页面，所以实际上我们还并没有进入到课程网站页面中去；   </p>
<p>为了便于分析，将 session.get() 到的对象转换成文本文件存储：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 存储函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_html</span><span class="params">(html)</span>:</span></span><br><span class="line">    f = open(<span class="string">'test.html'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    f.write(html)</span><br><span class="line">    f.close</span><br><span class="line"></span><br><span class="line"><span class="comment">### 调用</span></span><br><span class="line">url = <span class="string">"http://sep.ucas.ac.cn/portal/site/16/801"</span>   <span class="comment"># 跳转页面地址</span></span><br><span class="line">h_k = session.get(url)   <span class="comment"># 访问跳转，并获取返回的对象</span></span><br><span class="line">save_html(h_k.text) <span class="comment"># 转换为文本文件保存下来</span></span><br></pre></td></tr></table></figure></p>
<p>打开 h_k.text，我们知道跳转页面里，提示信息会有 “点击这里跳转” 这种选项，在这个文本里 <kbd>ctrl F</kbd>，输入：“跳转”，就可以看到，确实存在一个标签，如下：<br>（当然了，也可以在跳转的时候，强制停止刷新网页，然后在跳转页面用开发者模式查找 “这里” 这个字段的 href）<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"row-fluid"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">				<span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"span12"</span> <span class="attr">style</span>=<span class="string">"text-align:center;"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">					<span class="tag">&lt;<span class="name">h4</span>&gt;</span>2秒钟没有响应请点击<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"https://course.ucas.ac.cn/portal/plogin?Identity=fbd361f2-73cc-48b7-a5ec-37528b27a058&amp;roleId=801"</span>&gt;</span><span class="tag">&lt;<span class="name">strong</span>&gt;</span>这里<span class="tag">&lt;/<span class="name">strong</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span>直接跳转<span class="tag">&lt;/<span class="name">h4</span>&gt;</span></span><br><span class="line"></span><br><span class="line">				<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">           	<span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="comment">&lt;!--//container-fluid:end--&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>接下来，利用正则表达式，获取这个 url 里，Identity 的值（身份认证信息），重新构造 url，直接进入到课程网站页面：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用正则表达式找Request URL，Identity后的身份认证信息</span></span><br><span class="line">key = re.findall(<span class="string">r'"https://course.ucas.ac.cn/portal/plogin\?Identity=(.*)"'</span>, h_k.text)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">### 利用得到的身份认证信息，打开课程网站系统</span></span><br><span class="line">url = <span class="string">"http://course.ucas.ac.cn/portal/plogin/main/index?Identity="</span> + key</span><br><span class="line">page = session.get(url)</span><br><span class="line">print(<span class="string">'课程网站系统进入成功！'</span>)</span><br><span class="line"><span class="keyword">return</span> page</span><br></pre></td></tr></table></figure>
<h2 id="获取课程信息"><a href="#获取课程信息" class="headerlink" title="获取课程信息"></a>获取课程信息</h2><p>先进入主页：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用 BeautifulSoup 的 find_all 方法，找到课程网站的主页地址，并进入主页</span></span><br><span class="line">mycourseBS = BeautifulSoup(courseSite.text,<span class="string">"lxml"</span>) <span class="comment"># 利用 lxml 解析 text 文本</span></span><br><span class="line">url_mycourse = mycourseBS.find_all(<span class="string">'a'</span>,&#123;<span class="string">"class"</span>:<span class="string">'Mrphs-toolsNav__menuitem--link'</span>&#125;)[<span class="number">0</span>] <span class="comment"># 找 class 名为 xxx 的 a 标签</span></span><br><span class="line">url_mycourse = url_mycourse[<span class="string">"href"</span>] <span class="comment"># 获取 href ，即获取 url </span></span><br><span class="line">coursePage = session.get(url_mycourse)  <span class="comment"># 访问进入主页</span></span><br></pre></td></tr></table></figure>
<p>在我的课程里，获取课程信息：<br><img src="http://img.thebetterkong.cn/blog/CrawlSEPBatchDownload/courseinfo.jpg" alt="courseinfo"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用 BeautifulSoup 的 find_all 方法，在课程网站主页，寻找课程信息，并利用元组的形式记录在course_list中</span></span><br><span class="line">coursePageBS = BeautifulSoup(coursePage.text,<span class="string">"lxml"</span>) </span><br><span class="line">Course_info = coursePageBS.find_all(<span class="string">'li'</span>,&#123;<span class="string">"class"</span>:<span class="string">"fav-sites-entry"</span>&#125;)</span><br><span class="line">length = len(Course_info)   <span class="comment"># 标签数，即：课程总数</span></span><br><span class="line">print(<span class="string">"*****************************************************************"</span>)</span><br><span class="line">print(<span class="string">"所选课程总数为："</span>,length)</span><br><span class="line">print((<span class="string">"已选课程列表："</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,length<span class="number">-1</span>):</span><br><span class="line">    info = Course_info[i]</span><br><span class="line">    tag = info.div.a</span><br><span class="line">    courseName = tag[<span class="string">"title"</span>]  <span class="comment">#课程名字</span></span><br><span class="line">    print(<span class="string">"   "</span>,i,courseName)</span><br><span class="line">    courseUrl = tag[<span class="string">"href"</span>]   <span class="comment">#课程链接</span></span><br><span class="line">    course_list.append((courseName,courseUrl)) <span class="comment">#利用元组的形式保存</span></span><br><span class="line">print(<span class="string">"*****************************************************************"</span>)</span><br><span class="line"><span class="keyword">return</span> course_list</span><br></pre></td></tr></table></figure></p>
<h2 id="课件下载"><a href="#课件下载" class="headerlink" title="课件下载"></a>课件下载</h2><p>后面的页面跳转等处理，其实都类似，这里只介绍一些关键点，毕竟主要的目的在于学习：    </p>
<p>进入课程资源页面，这里直接将关键的 BeautifulSoup 查找语句列出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 访问进入某课程后，在课程页面里，利用 “资源” 模块的 title 查找，拿到其 href，即 url</span></span><br><span class="line">url = h_bs.find_all(title=<span class="string">"资源 - 上传、下载课件，发布文档，网址等信息"</span>)[<span class="number">0</span>].get(<span class="string">"href"</span>)</span><br></pre></td></tr></table></figure><br>查找所有资源链接：</p>
<ul>
<li>这里文件夹的处理，涉及到 onclick()，展开文件夹，更新 html 页面，但是这里我没态弄太明白，后面再琢磨。可以的话，可以在评论区给我留言一些相关知识讲解文章；</li>
</ul>
<p>下载文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### className：文件夹名</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_kj</span><span class="params">(url, fileName, className, session)</span>:</span></span><br><span class="line">    <span class="comment">### 文件名称处理</span></span><br><span class="line">    <span class="comment"># \xa0（不间断空白符&amp;nbsp）转gbk（汉字内码扩展规范）会有错，去掉；</span></span><br><span class="line">    fileName = fileName.replace(<span class="string">u"\xa0"</span>, <span class="string">" "</span>).replace(<span class="string">u"\xc2"</span>, <span class="string">""</span>)</span><br><span class="line">    <span class="comment"># 去掉不合法的文件名字符</span></span><br><span class="line">    fileName = re.sub(<span class="string">r"[/\\:*\"&lt;&gt;|?]"</span>, <span class="string">""</span>, fileName)</span><br><span class="line">    className = re.sub(<span class="string">r"[/\\:*\"&lt;&gt;|?]"</span>, <span class="string">""</span>, className)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 路径构造，os.getcwd()获取当前路径</span></span><br><span class="line">    dir = os.getcwd() + <span class="string">"/"</span> + className</span><br><span class="line">    file = os.getcwd() + <span class="string">"/"</span> + className + <span class="string">"/"</span> + fileName</span><br><span class="line">    <span class="comment"># 没有课程文件夹则创建</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir):</span><br><span class="line">        os.mkdir(dir)</span><br><span class="line">    <span class="comment"># 存在该文件，返回</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(file):</span><br><span class="line">        print(<span class="string">"%s已存在，就不下载了"</span> % fileName)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    print(<span class="string">"开始下载%s..."</span> % fileName)</span><br><span class="line">    s = session.get(url)</span><br><span class="line">    <span class="keyword">with</span> open(file, <span class="string">"wb"</span>) <span class="keyword">as</span> data:</span><br><span class="line">        data.write(s.content)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<h2 id="视频下载"><a href="#视频下载" class="headerlink" title="视频下载"></a>视频下载</h2><p>进入课程资源页面：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">h_bs = BeautifulSoup(h.text, <span class="string">"lxml"</span>)</span><br><span class="line">url = h_bs.find_all(title=<span class="string">"课程视频 - 课程视频"</span>)[<span class="number">0</span>].get(<span class="string">"href"</span>)</span><br></pre></td></tr></table></figure></p>
<p>又分为：课程视频（录播），直播视频（回放），这两部分处理方法一样，以第一项为例：</p>
<p>由于视频页可能包含多页，先抓取各个页的链接：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当时写的比较傻，采用循环加载下一页做的，其实可以直接抓取网页下面显示的页数，然后在原来 url 的基础上构造为： url+"&amp;pageNum="+i 即可；</span></span><br><span class="line">allpageURL.append(url)</span><br><span class="line">        flag =<span class="number">1</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> flag:</span><br><span class="line">            s = session.get(allpageURL[i])</span><br><span class="line">            page = re.search(<span class="string">'&lt;span&gt;&lt;a href="([^上]*?)"&gt;下一页&lt;/a&gt;&lt;/span&gt;'</span>,s.text, re.S)  <span class="comment"># 其实就是获取："&amp;pageNum="+i</span></span><br><span class="line">            <span class="keyword">if</span> page :</span><br><span class="line">                page = page.groups()[<span class="number">0</span>]</span><br><span class="line">                pageURL = <span class="string">'http://course.ucas.ac.cn'</span> + page</span><br><span class="line">                allpageURL.append(pageURL)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                flag = <span class="number">0</span></span><br><span class="line">            i = i+<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>接下来，就是循环在每页，不断的获取所有视频播放的 url，然后进入到播放页面，再找到视频源的 url 即可；    </p>
<p>视频下载：由于果壳大视频采用的 .m3u8 流媒体格式，我使用到了 ffmpeg（需要提前在电脑上安装）；用 subprocess 模块来产生子进程，调用 ffmpeg 完成下载；<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 按照获取到的视频链接调用ffmpeg进行下载，也可以尝试多进程下载，提高下载速度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_sp</span><span class="params">(spName, spUrl)</span>:</span></span><br><span class="line">    ins = <span class="string">'ffmpeg -i '</span> + spUrl + <span class="string">' -c copy '</span> + spName +<span class="string">'.mp4'</span></span><br><span class="line">    p = subprocess.Popen(ins)</span><br><span class="line">    p.wait()</span><br><span class="line">    print(<span class="string">'下载完毕'</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><p>其实这个脚本是挺久之前弄的了，但是总觉得之前边写边学，零零碎碎，慢慢的又觉得忘的差不多了。这当然不行，于是，重新梳理总结了一下当时的编写历程。     </p>
<p>通过这次，主要学习到的知识点：</p>
<ol>
<li>利用 webdriver 模拟登陆，以及遇到验证码时，将验证码抓取下来处理，并完成识别；</li>
<li>利用 session 构造 post 表单的方式，实现网站登录；</li>
<li>正则表达式的使用；</li>
<li>BeautifulSoup 的查找方法；</li>
<li>subprocess 的简单使用；</li>
<li>等等</li>
</ol>
<p>不足：</p>
<ul>
<li>还需要学习 js 的处理方法；</li>
</ul>
<p>最后还是需要强调一下，重在学习，利用脚本下载的资源，仅供自己学习使用，请不要传播！</p>
<ul>
<li>『<a href="https://github.com/TheBetterKong/UCAS_Sep" target="_blank" rel="noopener">脚本源码</a>』</li>
</ul>
<h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><ul>
<li>『<a href="https://zhuanlan.zhihu.com/p/94402506" target="_blank" rel="noopener">python实现网站的自动登录</a>』</li>
<li>『<a href="https://blog.csdn.net/lusongno1/article/details/79995009" target="_blank" rel="noopener">国科大（UCAS）课件自动批量下载 python3 脚本</a>』</li>
</ul>

    </div>

    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
      
    </div>
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="TheBetterKong 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="TheBetterKong 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>TheBetterKong
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://www.thebetterkong.cn/2020/05/22/Crawler/CrawlSEPBatchDownload/" title="利用爬虫实现课程网站资源的批量下载">http://www.thebetterkong.cn/2020/05/22/Crawler/CrawlSEPBatchDownload/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
              <a href="/tags/Crawler/" rel="tag"><i class="fa fa-tag"></i> Crawler</a>
              <a href="/tags/Webdriver/" rel="tag"><i class="fa fa-tag"></i> Webdriver</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/05/20/Blog-Related/ImproveMathJax/" rel="prev" title="改进 Hexo 中 MathJax 数学公式的渲染">
      <i class="fa fa-chevron-left"></i> 改进 Hexo 中 MathJax 数学公式的渲染
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/05/25/Literature-reading-notes/Morpheus-EMTDsWithChurn/" rel="next" title="《Morpheus:A Vulnerability-Tolerant Secure Architecture Based on EMTDs with Churn》阅读笔记">
      《Morpheus:A Vulnerability-Tolerant Secure Architecture Based on EMTDs with Churn》阅读笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前期准备"><span class="nav-number">1.</span> <span class="nav-text">前期准备</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#弯路：webdriver"><span class="nav-number">2.</span> <span class="nav-text">弯路：webdriver</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正文"><span class="nav-number">3.</span> <span class="nav-text">正文</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#网站登录"><span class="nav-number">3.1.</span> <span class="nav-text">网站登录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#进入课程网站"><span class="nav-number">3.2.</span> <span class="nav-text">进入课程网站</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#获取课程信息"><span class="nav-number">3.3.</span> <span class="nav-text">获取课程信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#课件下载"><span class="nav-number">3.4.</span> <span class="nav-text">课件下载</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#视频下载"><span class="nav-number">3.5.</span> <span class="nav-text">视频下载</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#写在最后"><span class="nav-number">4.</span> <span class="nav-text">写在最后</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考文章"><span class="nav-number">5.</span> <span class="nav-text">参考文章</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="TheBetterKong"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">TheBetterKong</p>
  <div class="site-description" itemprop="description">知行合一</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">50</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/TheBetterKong" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;TheBetterKong" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:kongxiangfeng@iie.ac.cn" title="E-Mail → mailto:kongxiangfeng@iie.ac.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/weixin_44849403" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;weixin_44849403" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/6460669623" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;6460669623" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://blog.cugxuan.cn/" title="https:&#x2F;&#x2F;blog.cugxuan.cn&#x2F;" rel="noopener" target="_blank">泫</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://paper.seebug.org/" title="https:&#x2F;&#x2F;paper.seebug.org&#x2F;" rel="noopener" target="_blank">Paper seebug</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.runoob.com/" title="https:&#x2F;&#x2F;www.runoob.com&#x2F;" rel="noopener" target="_blank">菜鸟教程</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://wiki.jikexueyuan.com/" title="https:&#x2F;&#x2F;wiki.jikexueyuan.com&#x2F;" rel="noopener" target="_blank">极客学院Wiki</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://man.linuxde.net/" title="https:&#x2F;&#x2F;man.linuxde.net&#x2F;" rel="noopener" target="_blank">Linux大全</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">鄂ICP备20005224号 </a>
  </div>

<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TheBetterKong</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>


<div class="statistics">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  <span id="busuanzi_value_site_uv"></span>
</span>
<span class ="post-meta-divider">|</span>
<i class="fa fa-eye"></i><span id="busuanzi_container_site_pv">
  <span id="busuanzi_value_site_pv"></span>
</span>
</div>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共226.1k字</span>
  <span class ="post-time-divider">|</span>
    <span>运行<span id="showDays"></span></span>
  <script>
    var seconds = 1000;
    var minutes = seconds * 60;
    var hours = minutes * 60;
    var days = hours * 24;
    var years = days * 365;
    var birthDay = Date.UTC(2020,04,20,18,00,00); // 这里设置建站时间
    setInterval(function() {
      var today = new Date();
      var todayYear = today.getFullYear();
      var todayMonth = today.getMonth()+1;
      var todayDate = today.getDate();
      var todayHour = today.getHours();
      var todayMinute = today.getMinutes();
      var todaySecond = today.getSeconds();
      var now = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
      var diff = now - birthDay;
      var diffYears = Math.floor(diff/years);
      var diffDays = Math.floor((diff/days)-diffYears*365);
      var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
      var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
      var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
      document.getElementById('showDays').innerHTML=""+diffYears+"年"+diffDays+"天"+diffHours+"小时"+diffMinutes+"分钟"+diffSeconds+"秒";
    }, 1000);
  </script>
</div>


        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'FzJ2kTqyh92urg7N9KHkL0RA-9Nh9j0Va',
      appKey     : 'aTVY6lFVOvNPNgaDGtgHVoQy',
      placeholder: "期待您的留言！",
      avatar     : '',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
